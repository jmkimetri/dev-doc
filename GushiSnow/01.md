## Kaldi에 관한 처리를 일본어 문서로 정리해 보았다 (데이터 준비편) 1
Kaldi의 음성 인식 요약
Kaldi는 DN (Deep Neural Network)을 이용한 음성 인식 시스템입니다.
학습에서 디코더까지 가능하지만 일본어 문서가 정비되어 있지 않으므로 비망록도 겸하여 기술해 둡니다.
중복 부분과 필자가 이해할 수없는 부분은 제외합니다.

voxforge를 예제로 순서대로 스크립트를 따라 살펴 보겠습니다.

사전 준비
1 : 여유 공간은 최소 20 ~ 25GB는 준비
2 : kaldi-trunk / egs / voxforge / s5 바로 아래 dir_test.txt
```bash
getdata.sh
```
위의 쉘이 있습니다.
데이터를 저장할 위치를 모르기 때문에,
```bash
path.sh
```
위의 스크립트를 엽니다.
```bash
#export KALDI_ROOT=`pwd`/../../..
export KALDI_ROOT=/home/tie303523/kaldi-trunk
export PATH=$PWD/utils/:$KALDI_ROOT/src/bin:$KALDI_ROOT/tools/openfst/bin:$KALDI_ROOT/src/fstbin/:$KALDI_ROOT/src/gmmbin/:$KALDI_ROOT/src/featbin/:$KALDI_ROOT/src/lm/:$KALDI_ROOT/src/sgmmbin/:$KALDI_ROOT/src/sgmm2bin/:$KALDI_ROOT/src/fgmmbin/:$KALDI_ROOT/src/latbin/:$PWD:$PATH

# VoxForge data will be stored in:
export DATA_ROOT="/home/dpovey/kaldi-clean/egs/voxforge/s5/voxforge"    # e.g. something like /media/secondary/voxforge

if [ -z $DATA_ROOT ]; then
  echo "You need to set \"DATA_ROOT\" variable in path.sh to point to the directory to host VoxForge's data"
  exit 1
fi

# Make sure that MITLM shared libs are found by the dynamic linker/loader
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$(pwd)/tools/mitlm-svn/lib

# Needed for "correct" sorting
export LC_ALL=C
```

위와 같은 스크립트가 나오므로 자신의 환경에 맞게 수정합니다.

설정한 PATH에 대해서, voxforge의 데이터가 취득된다.

클러스터 머신의 설정이 있으면 그 설정이 가능하지만, 지금은 스루

데이터 세트를 선택하는 쉘이 실행된다.
아래와 같은 종류로 분류가 가능(영어를 대상으로 하는 경우)

미국
영국
호주
뉴질랜드

local/voxforge_select.sh
그런 다음 익명 사용자의 데이터 세트와 사용자 ID를 매핑하는 셸 실행

local/voxforge_map_anonymous.sh
데이터 준비 스크립트가 실행됨
데이터를 학습 및 평가용으로 분할

local/voxforge_data_prep.sh
1 : 최초의 "-"의 기호까지 꺼내, 그 이름 speakers_all.txt에 출력
perl -ane ' s:.*/((.+)\-[0-9]{8,10}[a-z]*([_\-].*)?):$2: && print; ' | sort -u > $loctmp/speakers_all.txt 
2：그 중에서 테스트용으로 사용하는 데이터를 추출
utils/shuffle_list.pl <$loctmp/speakers_all.txt | head -n $nspk_test | sort -u >$loctmp/speakers_test.txtfor indirect one, use twice the learning rate
3: 학습용 데이터 추출
awk 'NR==FNR{spk[$0]; next} !($0 in spk)' \ 
$loctmp/speakers_test.txt $loctmp/speakers_all.txt |\
sort -u > $loctmp/speakers_train.txt
4：화자의 이름을 디렉토리명으로 생성한다
data/local/tmp/dir_train.txt
data/local/tmp/dir_test.txtfor indirect one, use twice the learning rate
5：아래와 같은 파일을 작성한다
-wave 파일의 위치와 wave 파일명을 기술한 wav.scp
- 음성 데이터와 음성 데이터에 대응한 쓰기 문장이 기술된 trans.txt -
음성 데이터와 화자의 대응이 기술된
에 대응하는 음성 데이터가 기술된 spk2utt

만들어집니다.

오류를 확인하려면 "make_trans.log"에 설명되어 있으므로 확인하십시오.

6 : 언어 모델을 작성한다.
ngram-count -order $order -write-vocab $locdata/vocab-full.txt -wbdiscount -text $loctmp/corpus.txt -lm $locdata/lm.arpa
바이그램 언어 모델이 생성된다.

7 : 단어에 음소를 부여한다. 다만 영어만이므로, 일본어의 경우는 이 부분의 개량이 필요! ! !
local/voxforge_prepare_dict.sh
이 스크립트로 사전 만들기(영어만 해당)

perl $locdict/cmudict/scripts/make_baseform.pl

vocab-oov.txt
lexicon-iv.txt

위의 파일을 만들고 음소 사전과 일반 텍스트에서 제거 된 파일을 만듭니다.

8：단어, 사전내의 출력 확률, 음소의 대응이 있는 파일을 작성
utils/prepare_lang.sh
9 : perl에서 다음과 같은 필요한 파일이 존재하고 적절한 형식인지 확인합니다.
lexicon.txt
silent_phones.txt
nonsilence_phones.txt
optional_silence.txt
간접적인 경우 학습률의 두 배 사용
pl
utils/validate_dict_dir.pl

10：음소에 위치마다의 라벨 첨부를 실시한다
_B: 소개
_E: 끝
_S: 단일
_I: 내부

lexiconp_disambig.txt 포맷으로 출력하는 처리를 본다.

형식은 아래

!EXCLAMATION-POINT 1.0 EH2_B K_I S_I K_I L_I AH0_I M_I EY1_I SH_I AH0_I N_I P_I OY2_I N_I T_E

단어 사전에 출현하고 있는지 여부 단어에 대응하는 음소 형태로 되어 있다.

음소와 음소 위치의 대응 관계가 기술된 word_boundary.txt를 작성한다.

단어와 단어 번호로 "words.txt"를 만듭니다.

lixicon.txt 사전의 출현 확률을 문자로 대체 한 "align_lexicon.txt"로 출력합니다.

여기에서는 OpenFst의 이야기도 포함되어 있으므로 다른 기사에 투고합니다.

계속되면 링크를 붙입니다.